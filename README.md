# **Thesis: IridesAI**

## **Overview**

Welcome to the **IridesAI** project repository! This repository contains the code, datasets, and resources developed as part of my thesis, titled **"IridesAI: Exploring Bias in AI-Generated Fiction for More Inclusive Storytelling."**

The project focuses on detecting and mitigating **cultural bias** in AI-generated fictional narratives produced by large language models (LLMs) such as **OpenAI's GPT-4, GPT-4-turbo, and GPT-3.5**. It aims to address how AI storytelling can perpetuate cultural dominance and stereotypes by reflecting values primarily from Western, English-speaking countries.

### **Primary Goals of the Research**:
1. **Cultural Bias Detection**: Analyzing the outputs of popular LLMs to assess how well they align with global cultural values using datasets such as the **World Values Survey (WVS)**.
2. **Cultural Prompting**: Developing and testing a strategy to mitigate cultural bias by adjusting AI model prompts to reflect the values of specific countries and cultures.
3. **Evaluation of AI Models**: Comparing cultural bias across different versions of GPT models, including **GPT-4o, GPT-4-turbo, GPT-4, and GPT-3.5**, and evaluating the effectiveness of cultural prompting in improving cultural alignment.
4. **Data-Driven Insights**: Providing insights into the presence and extent of cultural bias in AI-generated content, and offering a solution for more **inclusive, culturally aligned storytelling**.

---

### **Contents**
- **/code**: Python scripts and notebooks used for generating AI-generated narratives, applying cultural prompts, and analyzing cultural alignment.
- **/datasets**: Includes the **World Values Survey (WVS)** dataset and other relevant cultural data sources used for comparison.
- **/results**: Contains the results from running different models, including visualizations of cultural alignment across countries.
- **/docs**: Documentation on the methodologies used, including details on disaggregated evaluation, cultural prompting, and analysis techniques.
- **/reports**: Final thesis report and analysis write-ups.

---

### **Usage**
1. **Cultural Prompting and Evaluation**:
   - Use the provided scripts to generate fictional narratives from different **GPT models**.
   - Apply **cultural prompts** to modify the narrative outputs to reflect specific cultural contexts.
   
2. **Analyzing Cultural Bias**:
   - Scripts are provided to run **disaggregated evaluations** by comparing the generated outputs with the **World Values Survey** cultural data.

3. **Reproducing Results**:
   - Follow the instructions in the `README` file to reproduce the cultural alignment results presented in the thesis.

---

### **Key Features**
- **Multi-Model Comparison**: Compare the cultural biases present in outputs from various GPT models, from GPT-3 to GPT-4o.
- **Cultural Prompting**: Implement cultural prompting strategies to adjust AI-generated stories to better align with the values of specific countries and territories.
- **Data Visualization**: Automatically generate charts and graphs showing how AI narratives align (or misalign) with the cultural values from the **World Values Survey**.

---
